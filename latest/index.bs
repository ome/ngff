<pre class='metadata'>
Title: Next-generation file formats (NGFF)
Shortname: ome-ngff
Level: 1
Status: LS-COMMIT
Status: w3c/ED
Group: ome
URL: https://ngff.openmicroscopy.org/latest/
Repository: https://github.com/ome/ngff
Issue Tracking: Forums https://forum.image.sc/tag/ome-ngff
Logo: http://www.openmicroscopy.org/img/logos/ome-logomark.svg
Local Boilerplate: header yes
Local Boilerplate: copyright yes
Boilerplate: style-darkmode off
Markup Shorthands: markdown yes
Editor: Josh Moore, University of Dundee (UoD) https://www.dundee.ac.uk, https://orcid.org/0000-0003-4028-811X
Editor: Sébastien Besson, University of Dundee (UoD) https://www.dundee.ac.uk, https://orcid.org/0000-0001-8783-1429
Editor: Constantin Pape, European Molecular Biology Laboratory (EMBL) https://www.embl.org/sites/heidelberg/, https://orcid.org/0000-0001-6562-7187
Editor: John Bogovic, Hughes Medical Institute Janelia (HHMI) https://www.janelia.org/, https://orcid.org/0000-0002-4829-9457
Text Macro: NGFFVERSION 0.5-dev
Abstract: This document contains next-generation file format (NGFF)
Abstract: specifications for storing bioimaging data in the cloud.
Abstract: All specifications are submitted to the https://image.sc community for review.
Status Text: The current released version of this specification is
Status Text: <a href="../0.4/index.html">0.4</a>. Migration scripts
Status Text: will be provided between numbered versions. Data written with these latest changes
Status Text: (an "editor's draft") will not necessarily be supported.
</pre>

Introduction {#intro}
=====================

Bioimaging science is at a crossroads. Currently, the drive to acquire more,
larger, preciser spatial measurements is unfortunately at odds with our ability
to structure and share those measurements with others. During a global pandemic
more than ever, we believe fervently that global, collaborative discovery as
opposed to the post-publication, "data-on-request" mode of operation is the
path forward. Bioimaging data should be shareable via open and commercial cloud
resources without the need to download entire datasets.

At the moment, that is not the norm. The plethora of data formats produced by
imaging systems are ill-suited to remote sharing. Individual scientists
typically lack the infrastructure they need to host these data themselves. When
they acquire images from elsewhere, time-consuming translations and data
cleaning are needed to interpret findings. Those same costs are multiplied when
gathering data into online repositories where curator time can be the limiting
factor before publication is possible. Without a common effort, each lab or
resource is left building the tools they need and maintaining that
infrastructure often without dedicated funding.

This document defines a specification for bioimaging data to make it possible
to enable the conversion of proprietary formats into a common, cloud-ready one.
Such next-generation file formats layout data so that individual portions, or
"chunks", of large data are reference-able eliminating the need to download
entire datasets.


Why "<dfn export="true"><abbr title="Next-generation file-format">NGFF</abbr></dfn>"? {#why-ngff}
-------------------------------------------------------------------------------------------------

A short description of what is needed for an imaging format is "a hierarchy
of n-dimensional (dense) arrays with metadata". This combination of features
is certainly provided by <dfn export="true"><abbr title="Hierarchical Data Format 5">HDF5</abbr></dfn>
from the <a href="https://www.hdfgroup.org">HDF Group</a>, which a number of
bioimaging formats do use. HDF5 and other larger binary structures, however,
are ill-suited for storage in the cloud where accessing individual chunks
of data by name rather than seeking through a large file is at the heart of
parallelization.

As a result, a number of formats have been developed more recently which provide
the basic data structure of an HDF5 file, but do so in a more cloud-friendly way.
In the [PyData](https://pydata.org/) community, the Zarr [[zarr]] format was developed
for easily storing collections of [NumPy](https://numpy.org/) arrays. In the
[ImageJ](https://imagej.net/) community, N5 [[n5]] was developed to work around
the limitations of HDF5 ("N5" was originally short for "Not-HDF5").
Both of these formats permit storing individual chunks of data either locally in
separate files or in cloud-based object stores as separate keys.

A [current effort](https://zarr-specs.readthedocs.io/en/core-protocol-v3.0-dev/protocol/core/v3.0.html)
is underway to unify the two similar specifications to provide a single binary
specification. The editor's draft will soon be entering a [request for comments (RFC)](https://github.com/zarr-developers/zarr-specs/issues/101) phase with the goal of having a first version early in 2021. As that
process comes to an end, this document will be updated.

OME-NGFF {#ome-ngff}
--------------------

The conventions and specifications defined in this document are designed to
enable next-generation file formats to represent the same bioimaging data
that can be represented in \[OME-TIFF](http://www.openmicroscopy.org/ome-files/)
and beyond. However, the conventions will also be usable by HDF5 and other sufficiently advanced
binary containers. Eventually, we hope, the moniker "next-generation" will no longer be
applicable, and this will simply be the most efficient, common, and useful representation
of bioimaging data, whether during acquisition or sharing in the cloud.

Note: The following text makes use of OME-Zarr [[ome-zarr-py]], the current prototype implementation,
for all examples.

Document conventions
--------------------

The key words “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”,
“RECOMMENDED”, “MAY”, and “OPTIONAL” are to be interpreted as described in
[RFC 2119](https://tools.ietf.org/html/rfc2119).

<p>
<dfn>Transitional</dfn> metadata is added to the specification with the
intention of removing it in the future. Implementations may be expected (MUST) or
encouraged (SHOULD) to support the reading of the data, but writing will usually
be optional (MAY). Examples of transitional metadata include custom additions by
implementations that are later submitted as a formal specification. (See [[#bf2raw]])
</p>

Some of the JSON examples in this document include commments. However, these are only for
clarity purposes and comments MUST NOT be included in JSON objects.

On-disk (or in-cloud) layout {#on-disk}
=======================================

An overview of the layout of an OME-Zarr fileset should make
understanding the following metadata sections easier. The hierarchy
is represented here as it would appear locally but could equally
be stored on a web server to be accessed via HTTP or in object storage
like S3 or GCS.

OME-Zarr is an implementation of the OME-NGFF specification using the Zarr
format. Arrays MUST be defined and stored in a hierarchical organization as
defined by the
[version 2 of the Zarr specification ](https://zarr.readthedocs.io/en/stable/spec/v2.html).
OME-NGFF metadata MUST be stored as attributes in the corresponding Zarr
groups.

Images {#image-layout}
----------------------

The following layout describes the expected Zarr hierarchy for images with
multiple levels of resolutions and optionally associated labels.
See [[#multiscale-md]] for details.
For this example we assume an image with 5 dimensions and axes called `t,c,z,y,x`.

<pre>
.                             # Root folder, potentially in S3,
│                             # with a flat list of images by image ID.
│
├── 123.zarr                  # One image (id=123) converted to Zarr.
│
└── 456.zarr                  # Another image (id=456) converted to Zarr.
    │
    ├── .zgroup               # Each image is a Zarr group, or a folder, of other groups and arrays.
    ├── .zattrs               # Group level attributes are stored in the .zattrs file and include
    │                         # "multiscales" and "omero" (see below). In addition, the group level attributes
    │                         # must also contain "_ARRAY_DIMENSIONS" if this group directly contains multi-scale arrays.
    │
    ├── 0                     # Each multiscale level is stored as a separate Zarr array,
    │   ...                   # which is a folder containing chunk files which compose the array.
    ├── n                     # The name of the array is arbitrary with the ordering defined by
    │   │                     # by the "multiscales" metadata, but is often a sequence starting at 0.
    │   │
    │   ├── .zarray           
    │   │                     
    │   │
    │   └─ t                  # Chunks are stored with the nested directory layout.
    │      └─ c               # All but the last chunk element are stored as directories.
    │         └─ z            # The terminal chunk is a file. Together the directory and file names
    │            └─ y         # provide the "chunk coordinate" (t, c, z, y, x), where the maximum coordinate
    │               └─ x      # will be `dimension_size / chunk_size`.
    │
    └── labels
        │
        ├── .zgroup           # The labels group is a container which holds a list of labels to make the objects easily discoverable
        │
        ├── .zattrs           # All labels will be listed in `.zattrs` e.g. `{ "labels": [ "original/0" ] }`
        │                     # Each dimension of the label should be either the same as the
        │                     # corresponding dimension of the image, or `1` if that dimension of the label
        │                     # is irrelevant.
        │
        └── original          # Intermediate folders are permitted but not necessary and currently contain no extra metadata.
            │
            └── 0             # Multiscale, labeled image. The name is unimportant but is registered in the "labels" group above.
                ├── .zgroup   # Zarr Group which is both a multiscaled image as well as a labeled image.
                ├── .zattrs   # Metadata of the related image and as well as display information under the "image-label" key.
                │
                ├── 0         # Each multiscale level is stored as a separate Zarr array, as above, but only integer values
                │   ...       # are supported.
                └── n
</pre>



High-content screening {#hcs-layout}
------------------------------------

The following specification defines the hierarchy for a high-content screening
dataset. Three groups must be defined above the images:

-   the group above the images defines the well and MUST implement the
    [well specification](#well-md). All images contained in a well are fields
    of view of the same well
-   the group above the well defines a row of wells
-   the group above the well row defines an entire plate i.e. a two-dimensional
    collection of wells organized in rows and columns. It MUST implement the
    [plate specification](#plate-md)


<pre>
.                             # Root folder, potentially in S3,
│
└── 5966.zarr                 # One plate (id=5966) converted to Zarr
    ├── .zgroup
    ├── .zattrs               # Implements "plate" specification
    ├── A                     # First row of the plate
    │   ├── .zgroup
    │   │
    │   ├── 1                 # First column of row A
    │   │   ├── .zgroup
    │   │   ├── .zattrs       # Implements "well" specification
    │   │   │
    │   │   ├── 0             # First field of view of well A1
    │   │   │   │
    │   │   │   ├── .zgroup
    │   │   │   ├── .zattrs   # Implements "multiscales", "omero"
    │   │   │   ├── 0
    │   │   │   │   ...       # Resolution levels
    │   │   │   ├── n
    │   │   │   └── labels    # Labels (optional)
    │   │   ├── ...           # Fields of view
    │   │   └── m
    │   ├── ...               # Columns
    │   └── 12
    ├── ...                   # Rows
    └── H
</pre>

Metadata {#metadata}
====================

The various `.zattrs` files throughout the above array hierarchy may contain metadata
keys as specified below for discovering certain types of data, especially images.

"bioformats2raw.layout" (transitional) {#bf2raw}
------------------------------------------------

[=Transitional=] "bioformats2raw.layout" metadata identifies a group which implicitly describes a series of images.
The need for the collection stems from the common "multi-image file" scenario in microscopy. Parsers like Bio-Formats
define a strict, stable ordering of the images in a single container that can be used to refer to them by other tools.

In order to capture that information within an OME-NGFF dataset, `bioformats2raw` internally introduced a wrapping layer.
The bioformats2raw layout has been added to v0.4 as a transitional specification to specify filesets that already exist
in the wild. An upcoming NGFF specification will replace this layout with explicit metadata.

<h4 id="bf2raw-layout" class="no-toc">Layout</h4>

Typical Zarr layout produced by running `bioformats2raw` on a fileset that contains more than one image (series > 1):

<pre>
series.ome.zarr               # One converted fileset from bioformats2raw
    ├── .zgroup
    ├── .zattrs               # Contains "bioformats2raw.layout" metadata
    ├── OME                   # Special group for containing OME metadata
    │   ├── .zgroup
    │   ├── .zattrs           # Contains "series" metadata
    │   └── METADATA.ome.xml  # OME-XML file stored within the Zarr fileset
    ├── 0                     # First image in the collection
    ├── 1                     # Second image in the collection
    └── ...
</pre>

<h4 id="bf2raw-attributes" class="no-toc">Attributes</h4>

The top-level `.zattrs` file must contain the `bioformats2raw.layout` key:
<pre class=include-code>
path: examples/bf2raw/image.json
highlight: json
</pre>

If the top-level group represents a plate, the `bioformats2raw.layout` metadata will be present but
the "plate" key MUST also be present, takes precedence and parsing of such datasets should follow [[#plate-md]]. It is not
possible to mix collections of images with plates at present.

<pre class=include-code>
path: examples/bf2raw/plate.json
highlight: json
</pre>

The `.zattrs` file within the OME group may contain the "series" key:

<pre class=include-code>
path: examples/ome/series-2.json
highlight: json
</pre>

<h4 id="bf2raw-details" class="no-toc">Details</h4>

Conforming groups:

- MUST have the value "3" for the "bioformats2raw.layout" key in their `.zattrs` metadata at the top of the hierarchy;
- SHOULD have OME metadata representing the entire collection of images in a file named "OME/METADATA.ome.xml" which:
    - MUST adhere to the OME-XML specification but
    - MUST use `<MetadataOnly/>` elements as opposed to `<BinData/>`, `<BinaryOnly/>` or `<TiffData/>`;
    - MAY make use of the [minimum specification](https://docs.openmicroscopy.org/ome-model/6.2.2/specifications/minimum.html).

Additionally, the logic for finding the Zarr group for each image follows the following logic:

- If "plate" metadata is present, images MUST be located at the defined location.
    - Matching "series" metadata (as described next) SHOULD be provided for tools that are unaware of the "plate" specification.
- If the "OME" Zarr group exists, it:
    - MAY contain a "series" attribute. If so:
        - "series" MUST be a list of string objects, each of which is a path to an image group.
        - The order of the paths MUST match the order of the "Image" elements in "OME/METADATA.ome.xml" if provided.
- If the "series" attribute does not exist and no "plate" is present:
    - separate "multiscales" images MUST be stored in consecutively numbered groups starting from 0 (i.e. "0/", "1/", "2/", "3/", ...).
- Every "multiscales" group MUST represent exactly one OME-XML "Image" in the same order as either the series index or the group numbers.

Conforming readers:
- SHOULD make users aware of the presence of more than one image (i.e. SHOULD NOT default to only opening the first image);
- MAY use the "series" attribute in the "OME" group to determine a list of valid groups to display;
- MAY choose to show all images within the collection or offer the user a choice of images, as with <dfn export="true"><abbr title="High-content screening">HCS</abbr></dfn> plates;
- MAY ignore other groups or arrays under the root of the hierarchy.


"coordinateSystems" metadata {#coord-sys-md}
--------------------------

A "coordinate system" is a collection of "axes" / dimensions with a name. Every coordinate system:
- MUST contain the field "name". The value MUST be a non-empty string that is unique among `coordinateSystem`s.
- MUST contain the field "axes", whose value is an array of valid "axes" (see below).

<div class=example>

```json
{
    "name" : "volume_micrometers",
    "axes" : [
        {"name": "z", "type": "space", "unit": "micrometer"},
        {"name": "y", "type": "space", "unit": "micrometer"},
        {"name": "x", "type": "space", "unit": "micrometer"}
    ]
}
```
</div>

The order of the `"axes"` list matters and defines the index of each array dimension and coordinates for points in that
coordinate system. For the above example, the `"x"` dimension is the first dimension. The "dimensionality" of a coordinate system
is indicated by the length of its "axes" array. The "volume_micrometers" example coordinate system above is three dimensional (3D).

The axes of a coordinate system (see below) give information about the types, units, and other properties of the coordinate
system's dimensions. Axis `name`s may contain semantically meaningful information, but can be arbitrary. As a result, two
coordinate systems that have identical axes in the same order may not be "the same" in the sense that measurements at the same
point refer to different physical entities and therefore should not be analyzed jointly. Task that require images, annotations,
regions of interest, etc. SHOULD ensure that they are in the same coordinate system (same name, with identical axes) or can be
transformed to the same coordinate system before doing analysis. See the example below.

<div class=example>

Two instruments simultaneously image the same sample from two different angles, and the 3D data from both instruments are
calibrated to "micrometer" units. Two samples are collected ("sampleA" and "sampleB"). An analysis of sample A requires
measurements from both instruments' images at certain points in space. Suppose a region of interest (ROI) is determined from the
image obtained from instrument 2, but quantification from that region is needed for instrument 1. Since measurements were
collected at different angles, a measurement by instrument 1 at the point with coordinates (x,y,z) may not correspond to the
measurement at the same point in instrument 2 (i.e., it may not be the same physical location in the sample). To analyze both
images together, they must be in the same coordinate system.

The set of coordinate transformations ([[#trafo-md]]) encodes relationships between coordinate systems, specifically, how to
convert points and images to different coordinate systems.  Implementations can apply the coordinate transform to images or
points in coordinate system "sampleA_instrument2" to bring them into the "sampleA_instrument1" coordinate system. In this case,
the ROI should be transformed to the "sampleA_image1" coordinate system, then used for quantification with the instrument 1
image.

```json
"coordinateSystems" : [
    {
        "name" : "sampleA-instrument1",
        "axes" : [
            {"name": "z", "type": "space", "unit": "micrometer"},
            {"name": "y", "type": "space", "unit": "micrometer"},
            {"name": "x", "type": "space", "unit": "micrometer"}
        ]
    },
    {
        "name" : "sampleA-instrument2",
        "axes" : [
            {"name": "z", "type": "space", "unit": "micrometer"},
            {"name": "y", "type": "space", "unit": "micrometer"},
            {"name": "x", "type": "space", "unit": "micrometer"}
        ]
    }
],
"coordinateTransformations": [
    {
        "type": "affine":
        "path": "../sampleA_instrument2-to-instrument1"
        "input": "sampleA_instrument2",
        "output": "sampleA_instrument1"
    }
]
```

</div>



### "axes" metadata

"axes" describes the dimensions of a coordinate systems. It is a list of dictionaries, where each dictionary describes a dimension (axis) and:
- MUST contain the field "name" that gives the name for this dimension. The values MUST be unique across all "name" fields.
- SHOULD contain the field "type". It SHOULD be one of "array", "space", "time", "channel", "coordinate", or "displacement" but MAY take other values for custom axis types that are not part of this specification yet.
- MAY contain the field "discrete". The value MUST be a boolean, and is `true` if the axis represents a discrete dimension.
- SHOULD contain the field "unit" to specify the physical unit of this dimension. The value SHOULD be one of the following strings, which are valid units according to UDUNITS-2.
    - Units for "space" axes: 'angstrom', 'attometer', 'centimeter', 'decimeter', 'exameter', 'femtometer', 'foot', 'gigameter', 'hectometer', 'inch', 'kilometer', 'megameter', 'meter', 'micrometer', 'mile', 'millimeter', 'nanometer', 'parsec', 'petameter', 'picometer', 'terameter', 'yard', 'yoctometer', 'yottameter', 'zeptometer', 'zettameter'
    - Units for "time" axes: 'attosecond', 'centisecond', 'day', 'decisecond', 'exasecond', 'femtosecond', 'gigasecond', 'hectosecond', 'hour', 'kilosecond', 'megasecond', 'microsecond', 'millisecond', 'minute', 'nanosecond', 'petasecond', 'picosecond', 'second', 'terasecond', 'yoctosecond', 'yottasecond', 'zeptosecond', 'zettasecond'
- MAY contain the field "longName". The value MUST be a string, and can provide a longer name or description of an axis and its properties.

If part of [[#multiscale-md]], the length of "axes" MUST be equal to the number of dimensions of the arrays that contain the image data.

<div class=example>

Examples of valid axes:

```json
[
    {"name": "x", "type": "space", "unit": "micrometer"},
    {"name": "t", "type": "time", "unit": "second", "longName": "Unix Epoch time"},
    {"name": "c", "type": "channel", "discrete": true},
    {"name": "i0", "type": "array"},
    {"name": "c", "type": "coordinate", "discrete" : true },
    {"name": "v", "type": "displacement", "discrete": true },
    {"name": "freq", "type": "frequency", "unit": "megahertz"}
]
```
</div>

Arrays are often thought of as containing discrete samples along the continuous variable. Axes representing space and time are
usually continuous, meaning they can be indexed by real-valued (floating point) numbers whereas discrete axes may be indexed
only by integers. Arrays are inherently discrete (see Array coordinate systems, below) , but values "in between" discrete
coordinates can be retreived using an *interpolation* method.  If an axis is continuous (`"discrete" : false`), it indicates
that indexing with continuous values is meaningful, and that interpolation may be performed along that axis. Interpolation may
be performed jointly across axes with the same `type`, and interpolation should not be performed for discrete axes or jointly
across axes with differing `type`s.  Other non-continuous variables and axis types are also usually discrete, such as
`channel`s, `coordinate`s, and `displacement`s.

Note: The most common methods for interpolation are "nearest neighbor", "linear", "cubic", and "windowed sinc". Here, we refer
to any method that obtains values at real valued coordinates using discrete samples as an "interpolator". As such, label images
may be interpolated using "nearest neighbor" to obtain labels at points along the continuum.

<div class=example>

For the coordinate system:

```json
{
    "name" : "index and interpolation",
    "axes" : [
        {"name": "t", "type": "time"},
        {"name": "c", "type": "channel", "discrete": true},
        {"name": "y", "type": "space"},
        {"name": "x", "type": "space"}
    ]
}
```

Indexing an image at the point `(0.1, 0.2, 0.3, 0.4)` is not valid, because the value of the first coordinate (`0.1`) refers
to the discrete axis `"c"`.  Indexing an image at the point `(1, 0.2, 0.3, 0.4)` is valid.
</div>


### Array coordinate systems

Every array has a default coordinate system whose parameters need not be explicitly defined.  Its name is the path to the array
in the container, its axes have `"type":"array"`, are unitless, and have default "name"s. The ith axis has `"name":"dim_i"`
(these are the same default names used by [xarray](https://docs.xarray.dev/en/stable/user-guide/terminology.html)).
<div class=example>
For example, a 3D array at path `/my/data/array` defines the coordinate system:

```json
{
    "name" : "/my/data/array",
    "axes" : [
        {"name": "dim_0", "type": "array"},
        {"name": "dim_1", "type": "array"},
        {"name": "dim_2", "type": "array"}
    ]
}
```

though this object should not and need not explicitly appear in metadata. 
</div>


The dimensionality of each array coordinate system equals the dimensionality of its corresponding zarr array.  The axis with
name `"dim_i"` is the ith element of the `"axes"` list. The axes and their order align with the `shape`
attribute in the zarr array attributes (in `.zarray`), and whose data depends on the byte order used to store
chunks. As described in the [zarr array metadata](https://zarr.readthedocs.io/en/stable/spec/v2.html#arrays),
the last dimension of an array in "C" order (row-major) are stored contiguously. For an array in "F"
(column-major) order, the elements of the first dimension are stored contiguously.

<div class=example>
For example, if `/my/data/array/.zarray` contains:

```json
{
    "chunks": [ 4, 3, 5 ],
    "compressor": null,
    "dtype": "|u1",
    "fill_value": 0,
    "filters": null,
    "order": "C",
    "shape": [ 4, 3, 5 ],
    "zarr_format": 2
}
```

Then `dim_0` has length 4, `dim_1` has length 3, and `dim_2` has length 5.
</div>

The name and axes names MAY be customized by including a `arrayCoordinateSystem` field in
the `.zattr` metadata of the array whose value is a coordinate system object. The length of
`axes` MUST be equal to the dimensionality. The value of `"type"` for each object in the 
axes array MUST equal `"array"`.

<div class=example>

<pre class=include-code>
path: examples/coordSystems/arrayCoordSys.json
highlight: json
</pre>

</div>


### Coordinate convention

**The pixel/voxel center is the origin of the continuous coordinate system.**

It is vital to consistently define relationship between the discrete/array and continuous/interpolated
coordinate systems. A pixel/voxel is the continuous region (rectangle) that corresponds to a single sample
in the discrete array, i.e., the area corresponding to nearest-neighbor (NN) interpolation of that sample.
The center of a 2d pixel corresponding to the origin `(0,0)` in the discrete array is the origin of the continuous coordinate
system `(0.0, 0.0)` (when the transformation is the identity). The continuous rectangle of the pixel is given by the
half-open interval `[-0.5, 0.5) x [-0.5, 0.5)` (i.e., -0.5 is included, +0.5 is excluded). See chapter 4 and figure 4.1 of the ITK Software Guide [[itk]].



"coordinateTransformations" metadata {#trafo-md}
------------------------------------------------

"coordinateTransformations" describe the mapping between two coordinate systems (defined by "axes").
For example, to map an array's discrete coordinate system to its corresponding physical coordinates.
Coordinate transforms are in the "forward" direction. They represent functions from *points* in the
input space to *points* in the output space. 


- MUST contain the field "type".
- MUST contain any other fields required by the given "type" (see table below).
- MUST contain the field "output", unless part of a `sequence` or `inverseOf` (see details).
- MUST contain the field "input", unless part of a `sequence` or `inverseOf` (see details).
- MAY contain the field "name". Its value MUST be unique across all "name" fields for coordinate transformations.
- Parameter values MUST be compatible with input and output space dimensionality (see details).

<table>
  <tr><th>`identity`
    <td> 
    <td>The identity transformation is the default transformation and is typically not explicitly defined.
  <tr><th>`mapIndex`
    <td>`"mapIndex":List[number]`
    <td> A `mapIndex` transformation specifies an axis permutation by reordering the input axes.
  <tr><th>`mapAxis`
    <td>`"mapAxis":Dict[String:String]`
    <td> A `maxAxis` transformation specifies an axis permutation as a map between axis names.
  <tr><th>`translation`
    <td> one of: <br>`"translation":List[number]`, <br>`"path":str`
    <td>translation vector, stored either as a list of numbers (`"translation"`) or as binary data at a location
    in this container (`path`).
  <tr><th>`scale`
    <td> one of: <br>`"scale":List[number]`, <br>`"path":str`
    <td>scale vector, stored either as a list of numbers (`scale`) or as binary data at a location in this
    container (`path`).
  <tr><th>`affine`
    <td> one of: <br>`"affine":List[number]`, <br>`"path":str`
    <td>affine transformation matrix stored as a flat array stored either with json uing the affine field
    or as binary data at a location in this container (path). If both are present, the binary values at path should be used.
  <tr><th>`rotation`
    <td> one of: <br>`"rotation":List[number]`, <br>`"path":str`
    <td>rotation transformation matrix stored as an array stored either
        with json or as binary data at a location in this container (path).
        If both are present, the binary parameters at path are used.
  <tr><th>`sequence`
    <td> `"transformations":List[Transformation]`
    <td>A sequence of transformations, Applying the sequence applies the composition of all transforms in the list, in order.
  <tr><th>`displacements`
    <td>`"path":str`<br>`"interpolation":str`
    <td>Displacement field transformation located at (path).
  <tr><th>`coordinates`
    <td>`"path":str`<br>`"interpolation":str`
    <td>Coordinate field transformation located at (path).
  <tr><th>`inverseOf`
    <td>`"transform":Transform`
    <td>The inverse of a transformation. Useful if a transform is not closed-form invertible.  See Forward and inverse for details and examples.
  <tr><th>`bijection`
    <td>`"forward":Transform`<br>`"inverse":Transform`
    <td>Explicitly define an invertible transformation by providing a forward transformation and its inverse.
  <tr><th>`byDimension`
    <td>`"transformations":List[Transformation]`
    <td>Define a high dimensional transformation using lower dimensional transformations on subsets of
    dimensions.
 <thead>
   <tr><th>type<th>fields<th>description
</table>


Conforming readers:
- MUST parse `identity`, `scale`, `translation` transformations;
- SHOULD parse `mapAxis`, `affine` transformations;
- SHOULD be able to apply transformations to points;
- SHOULD be able to apply transformations to images;

Coordinate transformations from array to physical coordinates MUST be stored in multiscales ([[#multiscale-md]]),
and MUST be duplicated in the atrributes of the zarr array. Transformations between different images MUST be stored in the
attributes of a parent zarr group. For transformations that store data or parameters in a zarr array, those zarr arrays SHOULD
be stored in a zarr group `"coordinateTransformations"`.

<pre>
store.zarr                      # Root folder of the zarr store
│
├── .zattrs                     # coordinate transformations describing the relationship between two image coordinate systems
│                               # are stored in the attributes of their parent group.
│                               # transformations between 'volume' and 'crop' coordinate systems are stored here.
│
├── coordinateTransformations   # transformations that use array storage go in a "coordinateTransformations" zarr group.
│   └── displacements           # for example, a zarr array containing a displacement field
│       ├── .zattrs
│       └── .zarray
│
├── volume
│   ├── .zattrs                 # group level attributes (multiscales)
│   └── 0                       # a group containing the 0th scale
│       └── image               # a zarr array
│           ├── .zattrs         # physical coordinate system and transformations here
│           └── .zarray         # the array attributes
└── crop
    ├── .zattrs                 # group level attributes (multiscales)
    └── 0                       # a group containing the 0th scale
        └── image               # a zarr array
            ├── .zattrs         # physical coordinate system and transformations here
            └── .zarray         # the array attributes
</pre>

### Additional details

Most coordinate transformations MUST specify their input and output coordinate systems using `input` and `output` with a string value
corresponding to the name of a coordinate system. The coordinate system's name may be the path to an array, and therefore may
not appear in the list of coordinate systems.

Exceptions are if the the coordinate transformation appears in the `transformations` list of a `sequence` or is the
`transformation` of an `inverseOf` transformation. In these two cases input and output SHOULD be omitted (see below for
details).

Transformations in the `transformations` list of a `byDimensions` transformation MUST provide `input` and `output` as arrays
of strings corresponding to axis names of the parent transformation's input and output coordinate systems (see below for
details).

<div class=example>

The sequence transformation's input corresponds to an array coordinate system at path "/my/array".

```json
"coordinateSystems" : [
    { "name" : "in", "axes" : [{"name" : "i"}, {"name":"j"}] },
    { "name" : "outScale", "axes" : [{"name" : "x"}, {"name":"y"}] },
    { "name" : "outSeq", "axes" : [{"name" : "x"}, {"name":"y"}] },
    { "name" : "outInv", "axes" : [{"name" : "x"}, {"name":"y"}] },
    { "name" : "outByDim", "axes" : [{"name" : "x"}, {"name":"y"}] }
],
"coordinateTransformations" : [
    {
        "type": "scale",
        "input" : "in",
        "output" : "outScale",
        "scale" : [ 0.5, 1.2 ]
    },
    {
        "type" : "sequence",
        "input" : "/my/array",
        "output" : "outSeq",
        "transformations" : [
            { "type": "scale", "scale" : [ 0.5, 0.6 ] },
            { "type": "translation", "translation" : [ 2, 5 ] }
        ]
    },
    {
        "type": "inverseOf",
        "input" : "in",
        "output" : "outInv",
        "transformation" : {
            "type": "displacements",
            "path": "/path/to/displacements"
        }
    },
    {
        "type": "byDimension",
        "input" : "in",
        "output" : "outDim",
        "transformations" : [
            { "type" : "translation", "translation" : [1], "input" : ["i"], "output" : ["x"]},
            { "type" : "scale", "scale" : [2.0], "input" : ["j"], "output" : ["y"]}
        ]
    }
]
```

</div>

Coordinate transformations are functions of *points* in the input space to *points* in the output space. We call this the "forward" direction.
Points are ordered lists of coordinates, where a coordinate is the location/value of that point along its corresponding axis.
The indexes of axis dimensions correspond to indexes into transformation parameter arrays. For example, the scale transformation above
defines the function:

```
x = 0.5 * i
y = 1.2 * j
```

i.e., the mapping from the first input axis to the first output axis is determined by the first scale parameter.

When rendering transformed images and interpolating, implementations may need the "inverse" transformation - from the output to
the input coordinate system. Inverse transformations will not be explicitly specified when they can be computed in closed form from the
forward transformation. Inverse transformations used for image rendering should be specified using the `inverseOf`
transformation type, for example:

```json
{
    "type": "inverseOf",
    "transformation" : {
        "type": "displacements",
        "path": "/path/to/displacements",
    }
}
```

Implementations SHOULD be able to compute and apply the inverse of some coordinate transformations when they
are computable in closed-form (as the [Transformation types](#transformation-types) section below indicates). If an
operation is requested that requires the inverse of a transformation that can not be inverted in closed-form,
implementations MAY estimate an inverse, or MAY output a warning that the requested operation is unsupported.


### Transformation types

Input and output dimensionality may be determined by the value of the "input" and "output" fields, respectively. If the value
of "input" is an array, it's length gives the input dimension, otherwise the length of "axes" for the coordinate
system with the name of the "input" value gives the input dimension.  If the value of "input" is an array, it's
length gives the input imension, otherwise it is given by the length of "axes" for the coordinate system with
the name of the "input".  If the value of "output" is an array, it's length gives the output dimension,
otherwise it is given by the length of "axes" for the coordinate system with the name of the "output".

#### identity

`identity` transformations map input coordinates to output coordinates without modification. The position of
the ith axis of the output coordinate system is set to the position of the ith axis of the input coordinate
system. `identity` transformations are invertible.

<div class=example>

<pre class=include-code>
path: examples/transformations/identity.json
highlight: json
</pre>

defines the function:

```
x = i
y = j
```

</div>

#### mapIndex

`mapIndex` transformations describe axis permutations as a reordering of the input dimensions.
Transformations MUST include a `mapIndex` field whose value is an array of integers. If the ith element of the array is j, it
means that output dimension i comes from input dimension j. The length of the `mapIndex` array MUST be equal to the
dimensionality of the output coordinate system. If the input coordinate system has dimension N, then every integer in that array
MUST be less than N.

<div class=example>

<pre class=include-code>
path: examples/transformations/mapIndex1.json
highlight: json
</pre>

The "equivalent to identity" transformation defines the function:

```
x = i
y = j
```

and the "permutation" transformation defines the function

```
x = j
y = i
```

</div>

<div class=example>

<pre class=include-code>
path: examples/transformations/mapIndex2.json
highlight: json
</pre>

The "projection_down" transformation defines the function:

```
x = b
```

and the "projection_up" transformation defines the function:

```
x = a
y = b
z = b
```

</div>

#### mapAxis

`mapAxis` transformations describe axis permutations as a mapping of axis names. Transformations MUST include a `mapAxis` field
whose value is an object, all of whose values are strings. If the object contains `"x":"i"`, then the transform sets the value 
of the output coordinate for axis "x" to the value of the coordinate of input axis "i" (think `x = i`). For every axis in its output coordinate
system, the `mapAxis` MUST have a corresponding field. For every value of the object there MUST be an axis of the input
coordinate system with that name.

<div class=example>

<pre class=include-code>
path: examples/transformations/mapAxis1.json
highlight: json
</pre>

The "equivalent to identity" transformation defines the function:

```
x = i
y = j
```

and the "permutation" transformation defines the function

```
x = j
y = i
```

</div>

<div class=example>

<pre class=include-code>
path: examples/transformations/mapAxis2.json
highlight: json
</pre>

The "projection_down" transformation defines the function:

```
x = b
```

and the "projection_up" transformation defines the function:

```
x = a
y = b
z = b
```
</div>

#### translation

`translation` transformations are special cases of affine transformations. When possible, a 
translation transformation should be preferred to its equivalent affine. Input and output dimensionality MUST be
identical and MUST equal the the length of the "translation" array (N). `translation` transformations are
invertible.

<dl>
  <dt><strong>path</strong></dt>
  <dd>  The path to a zarr-array containing the translation parameters.
	The array at this path MUST be 1D, and its length MUST be `N`.</dd>
  <dt><strong>scale</strong></dt>
  <dd> 	The scale parameters stored as a JSON list of numbers. The list MUST have length `N`.</dd>
</dl>

<div class=example>

<pre class=include-code>
path: examples/transformations/translation.json
highlight: json
</pre>

defines the function:

```
x = i + 9 
y = j - 1.42
```
</div>

#### scale

`scale` transformations are special cases of affine transformations. When possible, a scale transformation
SHOULD be defined to its equivalent affine. Input and output dimensionality MUST be identical and MUST equal
the the length of the "scale" array (N). Values in the `scale` array SHOULD be non-zero; in that case, `scale`
transformations are invertible.

<dl>
  <dt><strong>path</strong></dt>
  <dd>  The path to a zarr-array containing the scale parameters.
	The array at this path MUST be 1D, and its length MUST be `N`.</dd>
  <dt><strong>scale</strong></dt>
  <dd> 	The scale parameters stored as a JSON list of numbers. The list MUST have length `N`.</dd>
</dl>

<div class=example>

<pre class=include-code>
path: examples/transformations/scale.json
highlight: json
</pre>

defines the function:

```
x = 3.12 * i
y = 2 * j
```
</div>

#### affine

`affine` transformations from N-dimensional inputs to M-dimensional outputs are represented at `(N)x(M+1)`
matrices in homogeneous coordinates. This transformation type is invertible when `N` equals `M`.
The matrix may be stored as a 2D array (inner arrays represent the rows of the matrix) or as a 1D array (row-major).

<dl>
  <dt><strong>path</strong></dt>
  <dd>  The path to a zarr-array containing the affine parameters.
	The array at this path MUST be 1D or 2D. If 1D, its length MUST be `N*(M+1)`.
    If 2D its size must be `N x (M+1)`.</dd>
  <dt><strong>affine</strong></dt>
  <dd> 	The affine parameters stored in JSON. The matrix may be stored as a row-major flat array of numbers that MUST be
        length `N*(M+1)`, or as 2D nested array where the outer array MUST be length `N` and the inner arrays MUST be length `M+1`.</dd>
</dl>

<div class=example>
    A 2D-2D example:

    <pre class=include-code>
    path: examples/transformations/affine2d2d.json
    highlight: json
    </pre>

    defines the function:

    ```
    x = 1*i + 2*j + 3
    y = 4*i + 5*j + 6
    ```
</div>

<div class=example>
    An example with two dimensional inputs and three dimensional outputs.
    <pre class=include-code>
    path: examples/transformations/affine2d3d.json
    highlight: json
    </pre>

    defines the function:

    ```
    x = 1*i + 2*j + 3
    y = 4*i + 5*j + 6
    z = 7*i + 8*j + 9
    ```

    Using a nested 2D JSON array, the same transformation can be written:
    <pre class=include-code>
    path: examples/transformations/affine2d3d_nested.json
    highlight: json
    </pre>

</div>


#### rotation

`rotation` transformations are special cases of affine transformations.
When possible, a rotation transformation SHOULD be defined rather than
its equivalent affine. Input and output dimensionality (N) MUST be
identical and greater than 1. Rotations are stored as `NxN` matrices,
see below, and MUST have determinant equal to one, with orthonormal rows
and columns. The matrix may be stored as a 2D array (inner arrays represent
the rows of the matrix) or as a 1D array (row-major). `rotation` transformations
are invertible.

<dl>
  <dt><strong>path</strong></dt>
  <dd>  The path to an array containing the affine parameters.
	The array at this path MUST be 1D or 2D. If 1D, its length MUST be `N*N`,
    if 2D its size must be `N x N`.</dd>
  <dt><strong>rotation</strong></dt>
  <dd> 	The  parameters stored in JSON. The matrix may be stored as a row-major flat array of numbers that MUST be
        length `N*N`, or as 2D nested array where the outer array MUST be length `N` and the inner arrays MUST be length `N`.</dd>
</dl>

<div class=example>
    A 2D example

    <pre class=include-code>
    path: examples/transformations/rotation.json
    highlight: json
    </pre>

    defines the function:

    ```
    x = 0*i - 1*j
    y = 1*i + 0*j
    ```
</div>


#### inverseOf

An `inverseOf` transformation contains another transformation (often non-linear), and indicates that
transforming points from output to input coordinate systems is possible using the contained transformation.
Transforming points from the input to the output coordinate systems requires the inverse of the contained
transformation (if it exists).

<div class=note>
    Software libraries that perform image registration often return the transformation from fixed image
    coordinates to moving image coordinates, because this "inverse" transformation is most often required
    when rendering the transformed moving image. Results such as this should be enclosed in an `inverseOf`
    transformation. This enables the "outer" coordinate transformation to specify the moving image coordinates
    as `input` and fixed image coordinates as `output`, a choice that many users and developers find intuitive.
</div>


<div class=example>
For example 

    <pre class=include-code>
    path: examples/transformations/inverseOf.json
    highlight: json
    </pre>

</div>

#### sequence

A `sequence` transformation consists of an ordered array of coordinate transformations, and is invertible if and only if every
coordinate transform in the array is invertible.

<dl>
  <dt><strong>transformations</strong></dt>
  <dd>A non-empty array of transformations.</dd>
</dl>

The `input` and `output` fields SHOULD be omitted for transformations that are in the list of transformations of a `sequence`.

<div class=example>

This sequence:

<pre class=include-code>
path: examples/transformations/sequence.json
highlight: json
</pre>

describes the function

```
x = (i + 0.1) * 2
y = (j + 0.9) * 3
```

and is invertible.
</div>


#### coordinates and displacements

`coordinates` and `displacements` transformations store coordinates or displacements in an array and interpret them as a transformation.
Applying the transformation amounts to looking up the appropriate locations in the array and interpolating.
`coordinates` and `displacements` transformations are not invertible in general, but implementations
MAY approximate their inverses. Metadata for these coordinate transforms have the following field: 

<dl>
  <dt><strong>path</strong></dt>
  <dd>  The location of the coordinate array in this (or another) containter.</dd>
  <dt><strong>interpolation</strong></dt>
  <dd>  The `interpolation` attributes MAY be provided. It's value indicates
        the interpolation to use if transforing points not on the array's discrete grid.
        Values could be:
        <ul>
            <li><code>linear</code> (default)</li>
            <li><code>nearest</code></li>
            <li><code>cubic</code></li>
        </ul></dd>
</dl>

The array data at `path` MUST define space and coordinate transform metadata:

* space metadata MUST have exactly one axis with `"type" : "coordinate"`
* Every axis name in the `coordinateTransform`'s `input` MUST appear in the space
* The array dimension corresponding to the coordinate axis MUST have length greater than or equal to the dimensionality of the `coordinateTransform` `output`
* SHOULD have `name` equal to the `name` of the corresponding `coordinateTransform`.

For `coordinates`:

* If a `coordinates`' input space has dimensionality `N`, then the array data at `path` MUST have dimensionality equal to `(N + 1)`.
* coordinateSystem metadata MUST have exactly one axis with `"type" : "coordinate"`

For `displacements`:
* coordinateSystem metadata MUST have exactly one axis with `"type" : "displacement"`
* `input` and `output` MUST have an equal number of dimensions.

For example, in 1D:
```
{
    "name" : "a coordinate field transform",
    "type": "coordinates",
    "path" : "i2xCoordinates",
    "input" : "i",
    "output" : "x",
    "interpolation" : "nearest"
}
```

where we assume input spaces "i" and "x" are defined elsewhere.
Example metadata for the array data at path `coordinates` above:

```
{
    "coordinateSystems" : [
        {
            "name" : "a coordinate field transform",
            "axes" : [
                { "name": "i", "type": "space", "discrete": true },
                { "name": "c", "type": "coordinate", "discrete": true }
            ]
        } 
    ],
    "coordinateTransformations" : [
        {
            "type" : "identity",
            "output" : "a coordinate field transform"
        }
    ]
}
```

If the arrray in `coordinates` contains the data: `[-9, 9, 0]`, then this metadata defines the function:

```
x = 
    if ( i < 0.5 )                      -9
    else if ( i >= 0.5 and i < 1.5 )     9
    else if ( i >= 1.5 )                 0
```


A 1D example displacement field:
```
{
    "name" : "a displacement field transform",
    "type": "displacements",
    "path" : "displacements",
    "input" : "i",
    "output" : "x",
    "interpolation" : "linear"
}
```

where we assume input spaces "i" and "x" are defined elsewhere. 
Example metadata for the array data at path `displacements` above:

```
{
    "coordinateSystems" : [
        {
            "name" : "a coordinate field transform",
            "axes" : [
                { "name": "x", "type": "space", "unit" : "nanometer" },
                { "name": "d", "type": "displacement", "discrete": true }
            ]
        } 
    ],
    "coordinateTransformations" : [
        {
            "type" : "scale",
            "scale" : [2, 1],
            "output" : "a displacement field transform"
        }
    ]
}
```
If the arrray in `displacements` contains the data: `[-1, 0, 1]`, 
this transformation maps the point `[1.0]` to the point `[0.5]`. A scale
transformation maps the array coordinates to the "x" axis. Using the inverse
of the scale transform, we see that we need the position `0.5` in array coordinates.
The transformation specifies linear interpolation, which in this case yields
`(0.5 * -1) + (0.5 * 0) = -0.5`. That value gives us the displacement of the
input point, hence the output is `1.0 + (-0.5) = 0.5`.


#### byDimension

`byDimension` transformations build a high dimensional transformation using lower dimensional transformations
on subsets of dimensions.

<dl>
  <dt><strong>transformations</strong></dt>
  <dd>  A list of transformations, each of which applies to a (non-strict) subset of input and output dimensions (axes). 
        The values of `input` and `output` fields MUST be an array of strings.
        Every axis name in `input` MUST correspond to a name of some axis in this parent object's `input` coordinate system.
        Every axis name in the parent byDimension's `output` MUST appear in exactly one of its child transformations' `output`.
        </dd>
</dl>


<div class=example>

A valid `byDimension` transformation:

<pre class=include-code>
path: examples/transformations/byDimension1.json
highlight: json
</pre>

</div>

<div class=example>

Another valid `byDimension` transformation:

<pre class=include-code>
path: examples/transformations/byDimension2.json
highlight: json
</pre>

</div>

<div class=example>

This is an **invalid** `byDimension` transform:

<pre class=include-code>
path: examples/transformations/byDimensionInvalid1.json
highlight: json
</pre>

It is invalid for two reasons. First because input `0` used by the scale transformation is not an axis of the `byDimension` transformation's `input`. Second, the `x` axis of the `output` does not appear in the `output` of any child transformation.

</div>

<div class=example>

Another **invalid** `byDimension` transform:

<pre class=include-code>
path: examples/transformations/byDimensionInvalid2.json
highlight: json
</pre>

This transformation is invalid because the output axis `x` appears in more than one transformation in the `transformations` list.

</div>


#### bijection

A bijection transformation is an invertible transformation in which both the `forward` and `inverse` transformations
are explicitly defined. Each direction SHOULD be a transformation type that is not closed-form invertible.
Its' input and output spaces MUST have equal dimension. The input and output dimensions for the both the forward
and inverse transformations MUST match bijection's input and output space dimensions.

`input` and `output` fields MAY be omitted for the `forward` and `inverse` transformations, in which case
the `forward` transformation's `input` and `output` are understood to match the bijection's, and the `inverse`
transformation's `input` (`output`) matches the bijection's `output` (`input`), see the example below.

Practically, non-invertible transformations have finite extents, so bijection transforms should only be expected
to be correct / consistent for points that fall within those extents. It may not be correct for any point of
approprite dimensionality.

<div class=example>

For example

<pre class=include-code>
path: examples/transformations/bijection.json
highlight: json
</pre>

the input and output of the `forward` and `inverse` transformations are understoood to be:

<pre class=include-code>
path: examples/transformations/bijection_verbose.json
highlight: json
</pre>

</div>



"multiscales" metadata {#multiscale-md}
---------------------------------------

Metadata about an image can be found under the "multiscales" key in the group-level metadata. Here, "image" refers to a multidimensional array with two or more dimensions. It is stored in a multiple resolution representation.

"multiscales" contains a list of dictionaries where each entry describes a multiscale image.

Each "multiscales" dictionary MUST contain the field "axes", see the [axes section](#axes-metadata).
The length of "axes" must be greater than 1 and MUST equal the dimensionality of the zarr arrays storing the image data (see "datasets:path").
The "axes" field SHOULD contain 2 or 3 entries with "type:space".
The order of the entries MUST correspond to the order of dimensions of the zarr arrays. In addition, the entries SHOULD be ordered by "type" where the "time" axis must come first (if present), followed by the  "channel" or custom axis (if present) and the axes of type "space".
If there are three spatial axes where two correspond to the image plane ("yx") and images are stacked along the other axis ("z"), the spatial axes SHOULD be ordered as "zyx".

Each "multiscales" dictionary MUST contain the field "datasets", which is a list of dictionaries describing the arrays storing the individual resolution levels.
Each dictionary in "datasets" MUST contain the field "path", whose value contains the path to the array for this resolution relative
to the current zarr group. The "path"s MUST be ordered from largest (i.e. highest resolution) to smallest.

Each "datasets" dictionary MUST have the same number of dimensions. The number of dimensions and order MUST correspond to number and order of "axes".
Each dictionary in "datasets" MUST contain the field "coordinateTransformations", which contains a list of transformations that map the data coordinates to the physical coordinates (as specified by "axes") for this resolution level.
The transformations are defined according to [[#trafo-md]]. The transformation MUST only be of type `translation` or `scale`.
They MUST contain exactly one `scale` transformation that specifies the pixel size in physical units or time duration. If scaling information is not available or applicable for one of the axes, the value MUST express the scaling factor between the current resolution and the first resolution for the given axis, defaulting to 1.0 if there is no downsampling along the axis.
It MAY contain exactly one `translation` that specifies the offset from the origin in physical units. If `translation` is given it MUST be listed after `scale` to ensure that it is given in physical coordinates.
The length of the `scale` and `translation` array MUST be the same as the length of "axes".
The requirements (only `scale` and `translation`, restrictions on order) are in place to provide a simple mapping from data coordinates to physical coordinates while being compatible with the general transformation spec.

Each "multiscales" dictionary MAY contain the field "coordinateTransformations", describing transformations that are applied to all resolution levels in the same manner.
The transformations MUST follow the same rules about allowed types, order, etc. as in "datasets:coordinateTransformations" and are applied after them.
They can for example be used to specify the `scale` for a dimension that is the same for all resolutions.

Each "multiscales" dictionary SHOULD contain the field "name". It SHOULD contain the field "version", which indicates the version of the multiscale metadata of this image (current version is [NGFFVERSION]).

Each "multiscales" dictionary SHOULD contain the field "type", which gives the type of downscaling method used to generate the multiscale image pyramid.
It SHOULD contain the field "metadata", which contains a dictionary with additional information about the downscaling method.

<pre class=include-code>
path: examples/multiscales_strict/multiscales_example.json
highlight: json
</pre>


If only one multiscale is provided, use it. Otherwise, the user can choose by
name, using the first multiscale as a fallback:

```python
datasets = []
for named in multiscales:
    if named["name"] == "3D":
        datasets = [x["path"] for x in named["datasets"]]
        break
if not datasets:
    # Use the first by default. Or perhaps choose based on chunk size.
    datasets = [x["path"] for x in multiscales[0]["datasets"]]
```

"omero" metadata (transitional) {#omero-md}
-------------------------------------------

[=Transitional=] information specific to the channels of an image and how to render it
can be found under the "omero" key in the group-level metadata:

```json
"id": 1,                              # ID in OMERO
"name": "example.tif",                # Name as shown in the UI
"version": "0.5-dev",                 # Current version
"channels": [                         # Array matching the c dimension size
    {
        "active": true,
        "coefficient": 1,
        "color": "0000FF",
        "family": "linear",
        "inverted": false,
        "label": "LaminB1",
        "window": {
            "end": 1500,
            "max": 65535,
            "min": 0,
            "start": 0
        }
    }
],
"rdefs": {
    "defaultT": 0,                    # First timepoint to show the user
    "defaultZ": 118,                  # First Z section to show the user
    "model": "color"                  # "color" or "greyscale"
}
```

See https://docs.openmicroscopy.org/omero/5.6.1/developers/Web/WebGateway.html#imgdata
for more information.

"labels" metadata {#labels-md}
------------------------------

The special group "labels" found under an image Zarr contains the key `labels` containing
the paths to label objects which can be found underneath the group:

```json
{
  "labels": [
    "orphaned/0"
  ]
}
```

Unlisted groups MAY be labels.

"image-label" metadata {#label-md}
----------------------------------

Groups containing the `image-label` dictionary represent an image segmentation
in which each unique pixel value represents a separate segmented object.
`image-label` groups MUST also contain `multiscales` metadata and the two
"datasets" series MUST have the same number of entries.

The `image-label` dictionary SHOULD contain a `colors` key whose value MUST be a
list of JSON objects describing the unique label values. Each color object MUST
contain the `label-value` key whose value MUST be an integer specifying the
pixel value for that label. It MAY contain an `rgba` key whose value MUST be an array
of four integers between 0 and 255 `[uint8, uint8, uint8, uint8]` specifying the label
color as RGBA. All the values under the `label-value` key MUST be unique. Clients
who choose to not throw an error SHOULD ignore all except the _last_ entry.

Some implementations MAY represent overlapping labels by using a specially assigned
value, for example the highest integer available in the pixel range.

The `image-label` dictionary MAY contain a `properties` key whose value MUST be a
list of JSON objects which also describes the unique label values. Each property object
MUST contain the `label-value` key whose value MUST be an integer specifying the pixel
value for that label. Additionally, an arbitrary number of key-value pairs
MAY be present for each label value denoting associated metadata. Not all label
values must share the same key-value pairs within the properties list.

The `image-label` dictionary MAY contain a `source` key whose value MUST be a JSON
object containing information on the image the label is associated with. If included,
it MAY include a key `image` whose value MUST be a string specifying the relative
path to a Zarr image group. The default value is "../../" since most labels are stored
under a subgroup named "labels/" (see above).

The `image-label` dictionary SHOULD contain a `version` key whose value MUST be a string
specifying the version of the image-label specification.

<pre class=include-code>
path: examples/label_strict/colors_properties.json
highlight: json
</pre>

"plate" metadata {#plate-md}
----------------------------

For high-content screening datasets, the plate layout can be found under the
custom attributes of the plate group under the `plate` key in the group-level metadata.

The `plate` dictionary MAY contain an `acquisitions` key whose value MUST be a list of
JSON objects defining the acquisitions for a given plate to which wells can refer to. Each
acquisition object MUST contain an `id` key whose value MUST be an unique integer identifier
greater than or equal to 0 within the context of the plate to which fields of view can refer
to (see #well-md).
Each acquisition object SHOULD contain a `name` key whose value MUST be a string identifying
the name of the acquisition. Each acquisition object SHOULD contain a `maximumfieldcount`
key whose value MUST be a positive integer indicating the maximum number of fields of view for the
acquisition. Each acquisition object MAY contain a `description` key whose value MUST be a
string specifying a description for the acquisition. Each acquisition object MAY contain
a `starttime` and/or `endtime` key whose values MUST be integer epoch timestamps specifying
the start and/or end timestamp of the acquisition.

The `plate` dictionary MUST contain a `columns` key whose value MUST be a list of JSON objects
defining the columns of the plate. Each column object defines the properties of
the column at the index of the object in the list. Each column in the physical plate
MUST be defined, even if no wells in the column are defined. Each column object MUST
contain a `name` key whose value is a string specifying the column name. The `name` MUST
contain only alphanumeric characters, MUST be case-sensitive, and MUST NOT be a duplicate of any
other `name` in the `columns` list. Care SHOULD be taken to avoid collisions on
case-insensitive filesystems (e.g. avoid using both `Aa` and `aA`).

The `plate` dictionary SHOULD contain a `field_count` key whose value MUST be a positive integer
defining the maximum number of fields per view across all wells.

The `plate` dictionary SHOULD contain a `name` key whose value MUST be a string defining the
name of the plate.

The `plate` dictionary MUST contain a `rows` key whose value MUST be a list of JSON objects
defining the rows of the plate. Each row object defines the properties of
the row at the index of the object in the list. Each row in the physical plate
MUST be defined, even if no wells in the row are defined. Each defined row MUST
contain a `name` key whose value MUST be a string defining the row name. The `name` MUST
contain only alphanumeric characters, MUST be case-sensitive, and MUST NOT be a duplicate of any
other `name` in the `rows` list. Care SHOULD be taken to avoid collisions on
case-insensitive filesystems (e.g. avoid using both `Aa` and `aA`).

The `plate` dictionary SHOULD contain a `version` key whose value MUST be a string specifying the
version of the plate specification.

The `plate` dictionary MUST contain a `wells` key whose value MUST be a list of JSON objects
defining the wells of the plate. Each well object MUST contain a `path` key whose value MUST
be a string specifying the path to the well subgroup. The `path` MUST consist of a `name` in
the `rows` list, a file separator (`/`), and a `name` from the `columns` list, in that order.
The `path` MUST NOT contain additional leading or trailing directories.
Each well object MUST contain both a `rowIndex` key whose value MUST be an integer identifying
the index into the `rows` list and a `columnIndex` key whose value MUST be an integer indentifying
the index into the `columns` list. `rowIndex` and `columnIndex` MUST be 0-based. The
`rowIndex`, `columnIndex`, and `path` MUST all refer to the same row/column pair.

For example the following JSON object defines a plate with two acquisitions and
6 wells (2 rows and 3 columns), containing up to 2 fields of view per acquisition.

<pre class=include-code>
path: examples/plate_strict/plate_6wells.json
highlight: json
</pre>

The following JSON object defines a sparse plate with one acquisition and
2 wells in a 96 well plate, containing one field of view per acquisition.

<pre class=include-code>
path: examples/plate_strict/plate_2wells.json
highlight: json
</pre>

"well" metadata {#well-md}
--------------------------

For high-content screening datasets, the metadata about all fields of views
under a given well can be found under the "well" key in the attributes of the
well group.

The `well` dictionary MUST contain an `images` key whose value MUST be a list of JSON objects
specifying all fields of views for a given well. Each image object MUST contain a
`path` key whose value MUST be a string specifying the path to the field of view. The `path`
MUST contain only alphanumeric characters, MUST be case-sensitive, and MUST NOT be a duplicate
of any other `path` in the `images` list. If multiple acquisitions were performed in the plate,
it MUST contain an `acquisition` key whose value MUST be an integer identifying the acquisition
which MUST match one of the acquisition JSON objects defined in the plate metadata (see #plate-md).

The `well` dictionary SHOULD contain a `version` key whose value MUST be a string specifying the
version of the well specification.

For example the following JSON object defines a well with four fields of
view. The first two fields of view were part of the first acquisition while
the last two fields of view were part of the second acquisition.

<pre class=include-code>
path: examples/well_strict/well_4fields.json
highlight: json
</pre>

The following JSON object defines a well with two fields of view in a plate with
four acquisitions. The first field is part of the first acquisition, and the second
field is part of the last acquisition.

<pre class=include-code>
path: examples/well_strict/well_2fields.json
highlight: json
</pre>

Specification naming style {#naming-style}
==========================================

Multi-word keys in this specification should use the `camelCase` style.
NB: some parts of the specification don't obey this convention as they
were added before this was adopted, but they should be updated in due course.

Implementations {#implementations}
==================================

Projects which support reading and/or writing OME-NGFF data include:

<dl>

  <dt><strong>[bigdataviewer-ome-zarr](https://github.com/mobie/bigdataviewer-ome-zarr)</strong></dt>
  <dd>Fiji-plugin for reading OME-Zarr.</dd>

  <dt><strong>[bioformats2raw](https://github.com/glencoesoftware/bioformats2raw)</strong></dt>
  <dd>A performant, Bio-Formats image file format converter.</dd>

  <dt><strong>[omero-ms-zarr](https://github.com/ome/omero-ms-zarr)</strong></dt>
  <dd>A microservice for OMERO.server that converts images stored in OMERO to OME-Zarr files on the fly, served via a web API.</dd>

  <dt><strong>[idr-zarr-tools](https://github.com/IDR/idr-zarr-tools)</strong></dt>
  <dd>A full workflow demonstrating the conversion of IDR images to OME-Zarr images on S3.</dd>

  <dt><strong>[OMERO CLI Zarr plugin](https://github.com/ome/omero-cli-zarr)</strong></dt>
  <dd>An OMERO CLI plugin that converts images stored in OMERO.server into a local Zarr file.</dd>

  <dt><strong>[ome-zarr-py](https://github.com/ome/ome-zarr-py)</strong></dt>
  <dd>A napari plugin for reading ome-zarr files.</dd>

  <dt><strong>[vizarr](https://github.com/hms-dbmi/vizarr/)</strong></dt>
  <dd>A minimal, purely client-side program for viewing Zarr-based images with Viv & ImJoy.</dd>

</dl>

<img src="https://downloads.openmicroscopy.org/presentations/2020/Dundee/Workshops/NGFF/zarr_diagram/images/zarr-ome-diagram.png"
    alt="Diagram of related projects"/>

All implementations prevent an equivalent representation of a dataset which can be downloaded or uploaded freely. An interactive
version of this diagram is available from the [OME2020 Workshop](https://downloads.openmicroscopy.org/presentations/2020/Dundee/Workshops/NGFF/zarr_diagram/).
Mouseover the blackboxes representing the implementations above to get a quick tip on how to use them.

Note: If you would like to see your project listed, please open an issue or PR on the [ome/ngff](https://github.com/ome/ngff) repository.

Citing {#citing}
================

[Next-generation file format (NGFF) specifications for storing bioimaging data in the cloud.](https://ngff.openmicroscopy.org/0.4)
J. Moore, *et al*. Editors. Open Microscopy Environment Consortium, 8 February 2022.
This edition of the specification is [https://ngff.openmicroscopy.org/0.4/](https://ngff.openmicroscopy.org/0.4/]).
The latest edition is available at [https://ngff.openmicroscopy.org/latest/](https://ngff.openmicroscopy.org/latest/).
[(doi:10.5281/zenodo.4282107)](https://doi.org/10.5281/zenodo.4282107)

Version History {#history}
==========================

<table>
  <thead>
    <tr>
      <td>Revision</td>
      <td>Date</td>
      <td>Description</td>
    </tr>
  </thead>
  <tr>
    <td>0.4.1</td>
    <td>2022-09-26</td>
    <td>transitional metadata for image collections ("bioformats2raw.layout")</td>
  </tr>
  <tr>
    <td>0.4.0</td>
    <td>2022-02-08</td>
    <td>multiscales: add axes type, units and coordinateTransformations</td>
  </tr>
  <tr>
    <td>0.4.0</td>
    <td>2022-02-08</td>
    <td>plate: add rowIndex/columnIndex                </td>
  </tr>
  <tr>
    <td>0.3.0</td>
    <td>2021-08-24</td>
    <td>Add axes field to multiscale metadata     </td>
  </tr>
  <tr>
    <td>0.2.0</td>
    <td>2021-03-29</td>
    <td>Change chunk dimension separator to "/"   </td>
  </tr>
  <tr>
    <td>0.1.4</td>
    <td>2020-11-26</td>
    <td>Add HCS specification                      </td>
  </tr>
  <tr>
    <td>0.1.3</td>
    <td>2020-09-14</td>
    <td>Add labels specification                   </td>
  </tr>
  <tr>
    <td>0.1.2     </td>
    <td>2020-05-07</td>
    <td>Add description of "omero" metadata        </td>
  </tr>
  <tr>
    <td>0.1.1     </td>
    <td>2020-05-06</td>
    <td>Add info on the ordering of resolutions    </td>
  </tr>
  <tr>
    <td>0.1.0     </td>
    <td>2020-04-20</td>
    <td>First version for internal demo            </td>
  </tr>
</table>


<pre class="biblio">
{
  "blogNov2020": {
    "href": "https://blog.openmicroscopy.org/file-formats/community/2020/11/04/zarr-data/",
    "title": "Public OME-Zarr data (Nov. 2020)",
    "authors": [
      "OME Team"
    ],
    "status": "Informational",
    "publisher": "OME",
    "id": "blogNov2020",
    "date": "04 November 2020"
  },
  "imagesc26952": {
    "href": "https://forum.image.sc/t/ome-s-position-regarding-file-formats/26952",
    "title": "OME’s position regarding file formats",
    "authors": [
      "OME Team"
    ],
    "status": "Informational",
    "publisher": "OME",
    "id": "imagesc26952",
    "date": "19 June 2020"
  },
  "n5": {
    "id": "n5",
    "href": "https://github.com/saalfeldlab/n5/issues/62",
    "title": "N5---a scalable Java API for hierarchies of chunked n-dimensional tensors and structured meta-data",
    "status": "Informational",
    "authors": [
      "John A. Bogovic",
      "Igor Pisarev",
      "Philipp Hanslovsky",
      "Neil Thistlethwaite",
      "Stephan Saalfeld"
    ],
    "date": "2020"
  },
  "ome-zarr-py": {
    "id": "ome-zarr-py",
    "href": "https://doi.org/10.5281/zenodo.4113931",
    "title": "ome-zarr-py: Experimental implementation of next-generation file format (NGFF) specifications for storing bioimaging data in the cloud.",
    "status": "Informational",
    "publisher": "Zenodo",
    "authors": [
      "OME",
      "et al"
    ],
    "date": "06 October 2020"
  },
  "zarr": {
    "id": "zarr",
    "href": "https://doi.org/10.5281/zenodo.4069231",
    "title": "Zarr: An implementation of chunked, compressed, N-dimensional arrays for Python.",
    "status": "Informational",
    "publisher": "Zenodo",
    "authors": [
      "Alistair Miles",
      "et al"
    ],
    "date": "06 October 2020"
  },
  "itk":{
    "id": "itk-book",
    "href": "https://itk.org/ItkSoftwareGuide.pdf",
    "title": "The ITK Software Guide",
    "status": "Informational",
    "publisher": "ITK",
    "authors": [
      "Hans J. Johnson",
      "Matthew M. McCormick",
      "Luis Ibanez",
      "Insight Software Consortium"
    ],
    "date": "16 April 2021"
  }
}
</pre>
